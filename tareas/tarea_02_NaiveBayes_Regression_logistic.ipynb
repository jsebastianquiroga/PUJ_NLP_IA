{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/PUJ_NLP_IA/blob/main/tareas/tarea_02_NaiveBayes_Regression_logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VQn8rbdS6wQ",
        "outputId": "2eb25cbd-7e99-40b5-e51e-85e443ce411c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#montar el drive\n",
        "#https://stackoverflow.com/questions/48905127/importing-py-files-in-google-colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importar las librerías requeridas"
      ],
      "metadata": {
        "id": "9zeHkUEPT0_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import pdb\n",
        "#importar las librerias requeridas\n",
        "#importar de nltk el stemming que se puede usar para español\n",
        "import nltk\n",
        "from nltk.corpus import None\n",
        "from nltk.stem import None\n",
        "from nltk.tokenize import None\n",
        "import numpy as np\n",
        "\n",
        "import string\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwyl4NhZT0BH",
        "outputId": "7cc2d017-4330-4981-d8a0-c5c5fb4ccfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cargar los datos"
      ],
      "metadata": {
        "id": "SxOU1Z6aT9ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cargue del corpus\n",
        "import csv\n",
        "def load_data(file_name):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        \"file_name\" la ruta donde se puede encontrar el archivo de texto que contiene los trinos.\n",
        "    Output:\n",
        "        data_x: lista con los trinos\n",
        "        data_y: lista con las etiquetas/ variable objetivo\n",
        "    \"\"\"\n",
        "    data_x = []\n",
        "    data_y = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    with open(file_name) as file:\n",
        "        reader = None\n",
        "        for row in reader:\n",
        "          None\n",
        "          None\n",
        "    ### END CODE HERE ###\n",
        "    return data_x, data_y"
      ],
      "metadata": {
        "id": "CW5BsCbdT_Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/nlp_maestria_AI/Taller 1/tweets.csv\"\n",
        "data_x, data_y = load_data(file_name)\n",
        "print(\"datos_x = {}, datos_y = {}\".format(len(data_x), len(data_y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhG-yQhnZzVz",
        "outputId": "419caff1-fcff-420c-e6ce-167d92c9353e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datos_x = 2305, datos_y = 2305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Expected output:**\n",
        "```\n",
        "datos_x = 2305, datos_y = 2305\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ENzpETWHijC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convertir la variable objetivo"
      ],
      "metadata": {
        "id": "KkVd8wgvleAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convertir_variable_obj(lista):\n",
        "  \"\"\"\n",
        "  input:\n",
        "    \"lista\" que cotiene la etiqueta de la variable objetivo en formato string. Ejemplo: [\"neg\", \"pos\"]\n",
        "  Ouput:\n",
        "    \"y\" lista con la etiqueta de la variable objetivo en formato interger. Ejemplo: [1, 0, 0, 1]\n",
        "    tenga en cuenta que los valores neutros se transforman a 1\n",
        "  \"\"\"\n",
        "  y = []\n",
        "  ### START CODE HERE ###\n",
        "  for row in None:\n",
        "    if row == None\n",
        "      row = 1\n",
        "    elif row == None\n",
        "      row = 1\n",
        "    else:\n",
        "      row = None\n",
        "    y.append(None)\n",
        "  ### END CODE HERE ###\n",
        "  return y"
      ],
      "metadata": {
        "id": "uZD-Ss7klu-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = convertir_variable_obj(data_y)\n",
        "print(y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dwtxbvTmm2S",
        "outputId": "43d306c7-b1ab-4856-f67e-3ce7540d97d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "y = convertir_variable_obj(data_y)\n",
        "print(y[:5])\n",
        "output: [0, 1, 0, 0, 0]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "n18u8NQkjqr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dividir los datos en entrenamiento y prueba"
      ],
      "metadata": {
        "id": "fl-9twAJjngP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def train_validation_test_split(data, train_percent, test_percent):\n",
        "    \"\"\"\n",
        "    Splits the input data to  train/validation/test according to the percentage provided\n",
        "\n",
        "    Args:\n",
        "        data: Pre-processed and tokenized corpus, i.e. list of sentences.\n",
        "        train_percent: integer 0-100, defines the portion of input corpus allocated for training\n",
        "        test_percent: integer 0-100, defines the portion of input corpus allocated for validation\n",
        "\n",
        "        Note: train_percent + test_percent need to be = 100\n",
        "\n",
        "    Returns:\n",
        "        train_data: list of sentences, the training part of the corpus\n",
        "        test_data: list of sentences, the test part of the corpus\n",
        "    \"\"\"\n",
        "    # fixed seed here for reproducibility\n",
        "    random.seed(87)\n",
        "\n",
        "    # reshuffle all input sentences\n",
        "    random.shuffle(data)\n",
        "\n",
        "    train_size = int(len(data) * train_percent / 100)\n",
        "    train_data = data[0:train_size]\n",
        "\n",
        "    test_size = int(len(data) * test_percent / 100)\n",
        "    test_data = data[train_size:train_size + test_size]\n",
        "\n",
        "    return train_data, test_data"
      ],
      "metadata": {
        "id": "KAv5NDIWjnOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x = train_validation_test_split(data_x, 80, 20)\n",
        "train_y, test_y = train_validation_test_split(y, 80, 20)"
      ],
      "metadata": {
        "id": "282PY4d5kKoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_x = {}, test_x = {}\".format(len(train_x),len(test_x)))\n",
        "print(\"train_y = {}, test_y = {}\".format(len(train_y),len(test_y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUcswsIkULK",
        "outputId": "6f06ad2b-8a3a-47fd-c52d-63dd5a9ffd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x = 1844, test_x = 461\n",
            "train_y = 1844, test_y = 461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected ouput:**\n",
        "\n",
        "\n",
        "```\n",
        "print(\"train_x = {}, test_x = {}\".format(len(train_x),len(test_x)))\n",
        "print(\"train_y = {}, test_y = {}\".format(len(train_y),len(test_y)))\n",
        "Output:\n",
        "train_x = 1844, test_x = 461\n",
        "train_y = 1844, test_y = 461\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ai5ikl-GkDbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento de trinos"
      ],
      "metadata": {
        "id": "xl39EvGOpExe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    stemmer = None\n",
        "    stopwords_english = None\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = None\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = None\n",
        "    # remove hyperlinks\n",
        "    tweet = None\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = None\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = None  # stemming word\n",
        "            tweets_clean.append(None)\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "f-DF7jc7nRyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tweet = \"HÍPER DESCUENTO EN CAOBBI. No pierdas más tiempo con Pedidos ya. Usá Caobbi y date todos los gustos :)..\"\n",
        "\n",
        "# print cleaned tweet\n",
        "print(process_tweet(custom_tweet))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eHhXqwCodoy",
        "outputId": "826ea3cf-a655-430d-b301-d79d33343ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hip', 'descuent', 'caobbi', 'pierd', 'tiemp', 'ped', 'usa', 'caobbi', 'dat', 'gust', ':)', '..']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output:**\n",
        "\n",
        "\n",
        "```\n",
        "print(process_tweet(custom_tweet))\n",
        "['hip', 'descuent', 'caobbi', 'pierd', 'tiemp', 'ped', 'usa', 'caobbi', 'dat', 'gust', ':)', '..']\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vLg3W3cDl6ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tweets(result, tweets, ys):\n",
        "    '''\n",
        "    Input:\n",
        "        result: a dictionary that will be used to map each pair to its frequency\n",
        "        tweets: a list of tweets\n",
        "        ys: a list corresponding to the sentiment of each tweet (either 0 or 1)\n",
        "    Output:\n",
        "        result: a dictionary mapping each pair to its frequency\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    for y, tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            # define the key, which is the word and label tuple\n",
        "            pair = None\n",
        "\n",
        "            # if the key exists in the dictionary, increment the count\n",
        "            if pair in result:\n",
        "                result[pair] += None\n",
        "\n",
        "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
        "            else:\n",
        "                result[pair] = None\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "ZKf8y_KIpHdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing your function\n",
        "result = {}\n",
        "tweets = ['híper descuento', 'caobbi pierda tiempo', 'pedido usá caobbi date gusto :)..']\n",
        "ys = [1, 0, 0]\n",
        "print(count_tweets(result, tweets, ys))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUplSpUXpLaQ",
        "outputId": "2e0b6270-9a64-44cc-b4e9-95a6cec8eef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('hip', 1): 1, ('descuent', 1): 1, ('caobbi', 0): 2, ('pierd', 0): 1, ('tiemp', 0): 1, ('ped', 0): 1, ('usa', 0): 1, ('dat', 0): 1, ('gust', 0): 1, (':)', 0): 1, ('..', 0): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "print(count_tweets(result, tweets, ys))\n",
        "{('hip', 1): 1, ('descuent', 1): 1, ('caobbi', 0): 2, ('pierd', 0): 1, ('tiemp', 0): 1, ('ped', 0): 1, ('usa', 0): 1, ('dat', 0): 1, ('gust', 0): 1, (':)', 0): 1, ('..', 0): 1}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDp1Kv26mVAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the freqs dictionary for later uses\n",
        "freqs = count_tweets({}, train_x, train_y)"
      ],
      "metadata": {
        "id": "_MflDaE9pocn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Función apoyo entrenamiento de NV"
      ],
      "metadata": {
        "id": "OKLrKuwwsMsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup(freqs, word, label):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        word: the word to look up\n",
        "        label: the label corresponding to the word\n",
        "    Output:\n",
        "        n: the number of times the word with its corresponding label appears.\n",
        "    '''\n",
        "    n = 0  # freqs.get((word, label), 0)\n",
        "\n",
        "    pair = (word, label)\n",
        "    if (pair in freqs):\n",
        "        n = freqs[pair]\n",
        "\n",
        "    return n"
      ],
      "metadata": {
        "id": "bimDR7y0seGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo Naive Bayes"
      ],
      "metadata": {
        "id": "G4OkQtKdrt8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenar el modelo usando Naive Bayes"
      ],
      "metadata": {
        "id": "_ExmqIZDpv0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary from (word, label) to how often the word appears\n",
        "        train_x: a list of tweets\n",
        "        train_y: a list of labels correponding to the tweets (0,1)\n",
        "    Output:\n",
        "        logprior: the log prior. (equation 3 above)\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
        "    '''\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # calculate V, the number of unique words in the vocabulary\n",
        "    vocab = None\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calculate N_pos, N_neg, V_pos, V_neg\n",
        "    N_pos = N_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # if the label is positive (greater than zero)\n",
        "        if pair[1] > 0:\n",
        "\n",
        "            # Increment the number of positive words by the count for this (word, label) pair\n",
        "            N_pos += None\n",
        "\n",
        "        # else, the label is negative\n",
        "        else:\n",
        "\n",
        "            # increment the number of negative words by the count for this (word,label) pair\n",
        "            N_neg += None\n",
        "\n",
        "    # Calculate D, the number of documents\n",
        "    D = len(train_x)\n",
        "\n",
        "    # Calculate D_pos, the number of positive documents\n",
        "    D_pos = None\n",
        "\n",
        "    # Calculate D_neg, the number of negative documents\n",
        "    D_neg = None\n",
        "\n",
        "    # Calculate logprior\n",
        "    logprior = None\n",
        "\n",
        "    # For each word in the vocabulary...\n",
        "    for word in vocab:\n",
        "        # get the positive and negative frequency of the word\n",
        "        freq_pos = lookup(freqs, word, 1)\n",
        "        freq_neg = lookup(freqs, word, 0)\n",
        "\n",
        "        # calculate the probability that each word is positive, and negative\n",
        "        p_w_pos = None\n",
        "        p_w_neg = None\n",
        "\n",
        "        # calculate the log likelihood of the word\n",
        "        loglikelihood[word] = None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return logprior, loglikelihood"
      ],
      "metadata": {
        "id": "izpppYvfpvVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
        "print(\"logprior = {}, loglikelihood = {}\".format(logprior, len(loglikelihood)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0HOT7LpqVOh",
        "outputId": "8e070e67-c817-470c-ae08-24dfdaaa2dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprior = 0.6247650978423644, loglikelihood = 3542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "print(\"logprior = {}, loglikelihood = {}\".format(logprior, len(loglikelihood)))\n",
        "logprior = 0.6247650978423644, loglikelihood = 3542\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QBz4PjXRm4xF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predecir la polaridad de un trino usando NV"
      ],
      "metadata": {
        "id": "c5q_IpUmqdjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Output:\n",
        "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
        "\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # process the tweet to get a list of words\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    # initialize probability to zero\n",
        "    p = 0\n",
        "\n",
        "    # add the logprior\n",
        "    p += logprior\n",
        "\n",
        "    for word in word_l:\n",
        "\n",
        "        # check if the word exists in the loglikelihood dictionary\n",
        "        if word in loglikelihood:\n",
        "            # add the log likelihood of that word to the probability\n",
        "            p += None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "WDDluy5zqibw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with your own tweet.\n",
        "my_tweet = 'ayer te enojaste mucho por lo de Caobbi entonces tenías el Cabronavirus'\n",
        "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcH7vGnHqsQb",
        "outputId": "6528b01d-032e-4f09-fed5-c05c8faaf92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is -1.3200948312471894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "```\n",
        "-1.3200948312471894\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GFz9DfOLnpX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with your own tweet.\n",
        "my_tweet = 'estoy en el cielo y nunca me di cuenta gracias caobbi'\n",
        "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
        "print('The expected output is', p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ_xBFM0q5Hp",
        "outputId": "5ef56f83-df6a-476f-efe0-cee6014aff74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The expected output is 0.980709886971538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "0.980709886971538\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yUWD5i3qnyZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluar el desempeño del modelo"
      ],
      "metadata": {
        "id": "nu2yihRir0pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood, naive_bayes_predict=naive_bayes_predict):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: A list of tweets\n",
        "        test_y: the corresponding labels for the list of tweets\n",
        "        logprior: the logprior\n",
        "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly)/(total # of tweets)\n",
        "    \"\"\"\n",
        "    accuracy = 0  # return this properly\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    test_y = np.array(test_y)\n",
        "    y_hats = []\n",
        "    for tweet in test_x:\n",
        "        # if the prediction is > 0\n",
        "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
        "            # the predicted class is 1\n",
        "            y_hat_i = None\n",
        "        else:\n",
        "            # otherwise the predicted class is 0\n",
        "            y_hat_i = None\n",
        "\n",
        "        # append the predicted class to the list y_hats\n",
        "        None\n",
        "\n",
        "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
        "    error = None\n",
        "\n",
        "    # Accuracy is 1 minus the error\n",
        "    accuracy = None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "OGtSzXGLr4nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naive Bayes accuracy = %0.4f\" %\n",
        "      (test_naive_bayes(test_x, test_y, logprior, loglikelihood)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rGleYw-uUDw",
        "outputId": "ed1694b8-8153-47b1-bb76-204b90b19b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes accuracy = 0.6291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "```\n",
        "Naive Bayes accuracy = 0.6291\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JxQUDu6vpJR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##obtener la polaridad por palabras"
      ],
      "metadata": {
        "id": "ApAOkm8CCT0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ratio(freqs, word):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary containing the words\n",
        "\n",
        "    Output: a dictionary with keys 'positive', 'negative', and 'ratio'.\n",
        "        Example: {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "    '''\n",
        "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
        "    ### START CODE HERE ###\n",
        "    # use lookup() to find positive counts for the word (denoted by the integer 1)\n",
        "    pos_neg_ratio['positive'] = lookup(freqs, word, 1)\n",
        "\n",
        "    # use lookup() to find negative counts for the word (denoted by integer 0)\n",
        "    pos_neg_ratio['negative'] = lookup(freqs, word, 0)\n",
        "\n",
        "    # calculate the ratio of positive to negative counts for the word\n",
        "    pos_neg_ratio['ratio'] = None\n",
        "    ### END CODE HERE ###\n",
        "    return pos_neg_ratio"
      ],
      "metadata": {
        "id": "Mk_UZt_JCaee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ratio(freqs, 'antoj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI_ca19qCfsG",
        "outputId": "8dcf84fd-f422-44fb-898f-9dad80e2d121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0, 'positive': 7, 'ratio': 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "get_ratio(freqs, 'antoj')\n",
        "{'negative': 0, 'positive': 7, 'ratio': 8.0}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NDmKGszlpWDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Obtener la polaridad según el margen de analísis"
      ],
      "metadata": {
        "id": "4oQecEL7Cock"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_by_threshold(freqs, label, threshold, get_ratio=get_ratio):\n",
        "    '''\n",
        "    Input:\n",
        "        freqs: dictionary of words\n",
        "        label: 1 for positive, 0 for negative\n",
        "        threshold: ratio that will be used as the cutoff for including a word in the returned dictionary\n",
        "    Output:\n",
        "        word_list: dictionary containing the word and information on its positive count, negative count, and ratio of positive to negative counts.\n",
        "        example of a key value pair:\n",
        "        {'happi':\n",
        "            {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
        "        }\n",
        "    '''\n",
        "    word_list = {}\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    for key in freqs.keys():\n",
        "        word, _ = key\n",
        "\n",
        "        # get the positive/negative ratio for a word\n",
        "        pos_neg_ratio = get_ratio(freqs, word)\n",
        "\n",
        "        # if the label is 1 and the ratio is greater than or equal to the threshold...\n",
        "        if label == 1 and pos_neg_ratio['ratio'] >= threshold:\n",
        "\n",
        "            # Add the pos_neg_ratio to the dictionary\n",
        "            word_list[word] = None\n",
        "\n",
        "        # If the label is 0 and the pos_neg_ratio is less than or equal to the threshold...\n",
        "        elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
        "\n",
        "            # Add the pos_neg_ratio to the dictionary\n",
        "            word_list[word] = None\n",
        "\n",
        "        # otherwise, do not include this word in the list (do nothing)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return word_list"
      ],
      "metadata": {
        "id": "1s6Cm2UcCoGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function: find negative words at or below a threshold\n",
        "get_words_by_threshold(freqs, label=0, threshold=0.30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3D6W4EkC6Qs",
        "outputId": "6b9b7569-f584-433a-c7c8-180cc80067db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'12': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'aburr': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'cabez': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'drog': {'negative': 7, 'positive': 1, 'ratio': 0.25},\n",
              " 'entro': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'fot': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'hiz': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'infinit': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'merd': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
              " 'now': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
              " 'off': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'preci': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'present': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'produt': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'rap': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'rock': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
              " 'uns': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'vas': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " 'wach': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
              " '✌': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " '👉🏻': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " '👌': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
              " '🙌🏻': {'negative': 5, 'positive': 0, 'ratio': 0.16666666666666666},\n",
              " '🤦🏻\\u200d♂': {'negative': 5, 'positive': 0, 'ratio': 0.16666666666666666},\n",
              " '🤮': {'negative': 3, 'positive': 0, 'ratio': 0.25}}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "```\n",
        "get_words_by_threshold(freqs, label=0, threshold=0.30)\n",
        "\n",
        "{'12': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'aburr': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'cabez': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'drog': {'negative': 7, 'positive': 1, 'ratio': 0.25},\n",
        " 'entro': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'fot': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'hiz': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'infinit': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'merd': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
        " 'now': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
        " 'off': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'preci': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'present': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'produt': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'rap': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'rock': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
        " 'uns': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'vas': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " 'wach': {'negative': 4, 'positive': 0, 'ratio': 0.2},\n",
        " '✌': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " '👉🏻': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " '👌': {'negative': 3, 'positive': 0, 'ratio': 0.25},\n",
        " '🙌🏻': {'negative': 5, 'positive': 0, 'ratio': 0.16666666666666666},\n",
        " '🤦🏻\\u200d♂': {'negative': 5, 'positive': 0, 'ratio': 0.16666666666666666},\n",
        " '🤮': {'negative': 3, 'positive': 0, 'ratio': 0.25}}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "oZn3Mtwxpxqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your function; find positive words at or above a threshold\n",
        "get_words_by_threshold(freqs, label=1, threshold= 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nwsPyt1DH6O",
        "outputId": "b250057b-564c-4451-94e9-da1c7df78ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'antoj': {'negative': 0, 'positive': 7, 'ratio': 8.0},\n",
              " 'cag': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " 'cont': {'negative': 0, 'positive': 9, 'ratio': 10.0},\n",
              " 'dan': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " 'encim': {'negative': 0, 'positive': 7, 'ratio': 8.0},\n",
              " 'herman': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " 'igual': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " 'nadi': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " 'ou': {'negative': 0, 'positive': 10, 'ratio': 11.0},\n",
              " 'parec': {'negative': 0, 'positive': 10, 'ratio': 11.0},\n",
              " 'u': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " 'unas': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
              " '😭': {'negative': 3, 'positive': 28, 'ratio': 7.25}}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expect output**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "get_words_by_threshold(freqs, label=1, threshold= 7)\n",
        "\n",
        "{'antoj': {'negative': 0, 'positive': 7, 'ratio': 8.0},\n",
        " 'cag': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " 'cont': {'negative': 0, 'positive': 9, 'ratio': 10.0},\n",
        " 'dan': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " 'encim': {'negative': 0, 'positive': 7, 'ratio': 8.0},\n",
        " 'herman': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " 'igual': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " 'nadi': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " 'ou': {'negative': 0, 'positive': 10, 'ratio': 11.0},\n",
        " 'parec': {'negative': 0, 'positive': 10, 'ratio': 11.0},\n",
        " 'u': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " 'unas': {'negative': 0, 'positive': 6, 'ratio': 7.0},\n",
        " '😭': {'negative': 3, 'positive': 28, 'ratio': 7.25}}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "CKOa1zQFqNiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de regresion logistica"
      ],
      "metadata": {
        "id": "oxthsUm-vW2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##funcion sigmoid"
      ],
      "metadata": {
        "id": "jzPTjO81xwnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    '''\n",
        "    Input:\n",
        "        z: is the input (can be a scalar or an array)\n",
        "    Output:\n",
        "        h: the sigmoid of z\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # calculate the sigmoid of z\n",
        "    h = None\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return h"
      ],
      "metadata": {
        "id": "JFYcy7sSxvqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prueba_x = np.random.rand(10, 1)\n",
        "h = sigmoid(prueba_x)\n",
        "print(h.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVW1D0Ss5MTO",
        "outputId": "6686bbf8-6eff-40d6-cbf3-c7e9ddf90afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output**\n",
        "\n",
        "\n",
        "```\n",
        "print(h.shape)\n",
        "(10, 1)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QfiaUZXiMvJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementar el gradiente descendiente"
      ],
      "metadata": {
        "id": "A469MAucx5xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Input:\n",
        "        x: matrix of features which is (m,n+1)\n",
        "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
        "        theta: weight vector of dimension (n+1,1)\n",
        "        alpha: learning rate\n",
        "        num_iters: number of iterations you want to train your model for\n",
        "    Output:\n",
        "        J: the final cost\n",
        "        theta: your final weight vector\n",
        "    Hint: you might want to print the cost to make sure that it is going down.\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # get 'm', the number of rows in matrix x\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "\n",
        "        # get z, the dot product of x and theta\n",
        "        z = None\n",
        "\n",
        "        # get the sigmoid of z\n",
        "        h = None\n",
        "        # calculate the cost function\n",
        "        J = None\n",
        "\n",
        "        # update the weights theta\n",
        "        theta = None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    J = float(J)\n",
        "    return J, theta"
      ],
      "metadata": {
        "id": "SKFFjvZFx8rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a synthetic test case using numpy PRNG functions\n",
        "np.random.seed(1)\n",
        "# X input is 10 x 3 with ones for the bias terms\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "# Y Labels are 10 x 1\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
        "\n",
        "# Apply gradient descent\n",
        "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
        "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34qjmz1OyFgw",
        "outputId": "6136c81a-2550-41e6-a8f4-64da3447c5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.67094970.\n",
            "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected Output**\n",
        "\n",
        "\n",
        "```\n",
        "The cost after training is 0.67094970.\n",
        "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PU9_bbcPM-Gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##extracción de caracteristicas"
      ],
      "metadata": {
        "id": "TSx6WGAmyS-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output:\n",
        "        x: a feature vector of dimension (1,3)\n",
        "    '''\n",
        "    # process_tweet tokenizes, stems, and removes stopwords\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    # 3 elements in the form of a 1 x 3 vector\n",
        "    x = np.zeros((1, 3))\n",
        "\n",
        "    #bias term is set to 1\n",
        "    x[0,0] = 1\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # loop through each word in the list of words\n",
        "    for word in None:\n",
        "\n",
        "        # increment the word count for the positive label 1\n",
        "        x[0,1] += None\n",
        "\n",
        "        # increment the word count for the negative label 0\n",
        "        x[0,2] += None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ],
      "metadata": {
        "id": "dimWQaaNyOda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test on training data\n",
        "x = extract_features(train_x[0], freqs)\n",
        "print(train_x[0])\n",
        "#print(word_l)\n",
        "print(x[0])\n",
        "print(type(x[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75HIkH5FyZp9",
        "outputId": "8c90d303-edc6-4b93-c82c-dcf2025a5967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@JavierSiIva Caobbi puso oferta de hipogloss pa los que tienen el ano irritado\n",
            "[1.000e+00 1.211e+03 6.430e+02]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "@JavierSiIva Caobbi puso oferta de hipogloss pa los que tienen el ano irritado\n",
        "[1.000e+00 1.211e+03 6.430e+02]\n",
        "<class 'numpy.ndarray'>\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "0mhpWUfuNHz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento del modelo RL"
      ],
      "metadata": {
        "id": "Dw2tZ7WH-yrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "\n",
        "# Make sure that you have the correct type of data\n",
        "None\n",
        "None\n",
        "\n",
        "# Apply gradient descent\n",
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUKIBvaI0Vud",
        "outputId": "ae7b6878-758c-4a90-bc5f-929ee601988d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.67094970.\n",
            "The resulting vector of weights is [1.5e-07, 0.00019808, 0.00010069]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "The cost after training is 0.67094970.\n",
        "The resulting vector of weights is [1.5e-07, 0.00019808, 0.00010069]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7s0DIN7ZNTA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predecir la polaridad de un trino usando modelo RL"
      ],
      "metadata": {
        "id": "2ykQOKxV-2ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "        theta: (3,1) vector of weights\n",
        "    Output:\n",
        "        y_pred: the probability of a tweet being positive or negative\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # extract the features of the tweet and store it into x\n",
        "    x = None\n",
        "\n",
        "    # make the prediction using x and theta\n",
        "    y_pred = None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "SEV8Cqal-9ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to test your function\n",
        "for tweet in ['ayer te enojaste', 'mucho por lo de Caobbi entonces tenías el Cabronavirus', 'estoy en el cielo y nunca me di cuenta gracias caobbi']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phcU8Erw_RpP",
        "outputId": "0a044729-1daf-48cf-b3ba-5e3f1b80841f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ayer te enojaste -> 0.500374\n",
            "mucho por lo de Caobbi entonces tenías el Cabronavirus -> 0.574846\n",
            "estoy en el cielo y nunca me di cuenta gracias caobbi -> 0.578533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "ayer te enojaste -> 0.500374\n",
        "mucho por lo de Caobbi entonces tenías el Cabronavirus -> 0.574846\n",
        "estoy en el cielo y nunca me di cuenta gracias caobbi -> 0.578533\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Chnw0R3aNcSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluar el desempeño del modelo RL"
      ],
      "metadata": {
        "id": "WvN_1Sc-_mlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: a list of tweets\n",
        "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        theta: weight vector of dimension (3, 1)\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # the list for storing predictions\n",
        "    y_hat = []\n",
        "\n",
        "    for tweet in test_x:\n",
        "        # get the label prediction for the tweet\n",
        "        y_pred = None\n",
        "\n",
        "        if y_pred > 0.5:\n",
        "            # append 1.0 to the list\n",
        "            None\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            None\n",
        "\n",
        "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
        "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
        "    accuracy = None\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Slq4t6k3_rIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0P7ux2P_sk3",
        "outputId": "e4b86f75-7511-4e5d-c500-7d3ab8fcb6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model's accuracy = 0.6746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expected output**\n",
        "\n",
        "\n",
        "```\n",
        "Logistic regression model's accuracy = 0.6746\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Cdohl6ZgNkBV"
      }
    }
  ]
}